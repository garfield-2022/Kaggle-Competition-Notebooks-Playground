{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73278,"databundleVersionId":8121328,"sourceType":"competition"},{"sourceId":8337672,"sourceType":"datasetVersion","datasetId":4951648}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The 9 new features (total, min, std, max, min, median, ptp, q25, q75) are borrowed from PS4E5| OpenFE + Blending + Explain https://www.kaggle.com/code/trupologhelper/ps4e5-openfe-blending-explain. As discussed in this post https://www.kaggle.com/competitions/playground-series-s4e5/discussion/500032, we have a large dataset, therefore train-test-split is enough for cross validation. I learned how to use Optuna to do hyperparameter tuning from PS4E4 üèÜ| XGBoost+LIGHTGBM+CatBoostüòäüòäüòä https://www.kaggle.com/code/aaachen/ps4e4-xgboost-lightgbm-catboost in the last playground competition PS4E4 Regression with an Abalone Dataset.\n\nTo choose lgbm parameters and ranges: https://www.kaggle.com/code/aspillai/flood-prediction-regression-lightgbm-0-86931#Training-CV and https://www.kaggle.com/code/aspillai/flood-prediction-regression-lgb-xgb-cat-0-86933#Model-Training.","metadata":{}},{"cell_type":"markdown","source":"# 1. Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom warnings import filterwarnings;\nfilterwarnings('ignore');\n\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingRegressor\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nimport optuna\nfrom optuna.samplers import TPESampler","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:20.933828Z","iopub.execute_input":"2024-05-27T17:08:20.934654Z","iopub.status.idle":"2024-05-27T17:08:26.876975Z","shell.execute_reply.started":"2024-05-27T17:08:20.934619Z","shell.execute_reply":"2024-05-27T17:08:26.875902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\nimport lightgbm as lgb\n\nclass CustomLogger:\n    def init(self):\n        self.logger = logging.getLogger('lightgbm_custom')\n        self.logger.setLevel(logging.ERROR)\n\n    def info(self, message):\n        self.logger.info(message)\n\n    def warning(self, message):\n        # Suppress warnings by not doing anything\n        pass\n\n    def error(self, message):\n        self.logger.error(message)\n\n\nl = CustomLogger()\nl.init()\nlgb.register_logger(l)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:30.498281Z","iopub.execute_input":"2024-05-27T17:08:30.498659Z","iopub.status.idle":"2024-05-27T17:08:30.505668Z","shell.execute_reply.started":"2024-05-27T17:08:30.498632Z","shell.execute_reply":"2024-05-27T17:08:30.504532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Load data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv')\noriginal = pd.read_csv('/kaggle/input/original/flood.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:32.913007Z","iopub.execute_input":"2024-05-27T17:08:32.913450Z","iopub.status.idle":"2024-05-27T17:08:36.319995Z","shell.execute_reply.started":"2024-05-27T17:08:32.913415Z","shell.execute_reply":"2024-05-27T17:08:36.318883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop('id', axis=1, inplace=True)\ntrain = pd.concat([train, original], axis=0)\ntrain.reset_index(inplace=True, drop=True)\n\ntest_ID = test['id']\ntest.drop('id', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:36.321926Z","iopub.execute_input":"2024-05-27T17:08:36.322287Z","iopub.status.idle":"2024-05-27T17:08:36.518978Z","shell.execute_reply.started":"2024-05-27T17:08:36.322255Z","shell.execute_reply":"2024-05-27T17:08:36.517938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Feature Engineering","metadata":{}},{"cell_type":"code","source":"BASE_FEATURES = test.columns\ndef add_features(df):\n    \n    # These statistical features capture various aspects of the distribution and central tendencies of the base features for each row, providing additional insights for the model.\n    df['total'] = df[BASE_FEATURES].sum(axis=1)\n    df['mean'] = df[BASE_FEATURES].mean(axis=1)\n    df['std'] = df[BASE_FEATURES].std(axis=1)\n    df['max'] = df[BASE_FEATURES].max(axis=1)\n    df['min'] = df[BASE_FEATURES].min(axis=1)\n    df['median'] = df[BASE_FEATURES].median(axis=1)\n    df['ptp'] = df[BASE_FEATURES].values.ptp(axis=1)\n    df['q25'] = df[BASE_FEATURES].quantile(0.25, axis=1)\n    df['q75'] = df[BASE_FEATURES].quantile(0.75, axis=1)\n    \n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:38.352789Z","iopub.execute_input":"2024-05-27T17:08:38.353409Z","iopub.status.idle":"2024-05-27T17:08:46.200893Z","shell.execute_reply.started":"2024-05-27T17:08:38.353379Z","shell.execute_reply":"2024-05-27T17:08:46.199815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_index = train.index\ntest_index = test.index\n\nscaler = StandardScaler()\nscaler.fit(pd.concat([train.drop(columns=['FloodProbability']), test]))\n\ntrain_scaled = pd.DataFrame(scaler.transform(train.drop(columns=['FloodProbability'])), \n                            columns=train.drop(columns=['FloodProbability']).columns, \n                            index=train_index)\ntest_scaled = pd.DataFrame(scaler.transform(test), \n                           columns=test.columns, \n                           index=test_index)\n\ntrain = pd.concat([train_scaled, train['FloodProbability']], axis=1)\ntest = test_scaled","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:46.203109Z","iopub.execute_input":"2024-05-27T17:08:46.203869Z","iopub.status.idle":"2024-05-27T17:08:47.800779Z","shell.execute_reply.started":"2024-05-27T17:08:46.203831Z","shell.execute_reply":"2024-05-27T17:08:47.799915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Split data","metadata":{}},{"cell_type":"code","source":"X_train = train.drop(columns=['FloodProbability'])\ny_train = train['FloodProbability']","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:47.801838Z","iopub.execute_input":"2024-05-27T17:08:47.802122Z","iopub.status.idle":"2024-05-27T17:08:47.892483Z","shell.execute_reply.started":"2024-05-27T17:08:47.802099Z","shell.execute_reply":"2024-05-27T17:08:47.891236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:47.894865Z","iopub.execute_input":"2024-05-27T17:08:47.895229Z","iopub.status.idle":"2024-05-27T17:08:47.900148Z","shell.execute_reply.started":"2024-05-27T17:08:47.895199Z","shell.execute_reply":"2024-05-27T17:08:47.898977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stratify parameter keeps the ratio of FloodProbability same all across the Dataset\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:47.901840Z","iopub.execute_input":"2024-05-27T17:08:47.902313Z","iopub.status.idle":"2024-05-27T17:08:48.725017Z","shell.execute_reply.started":"2024-05-27T17:08:47.902276Z","shell.execute_reply":"2024-05-27T17:08:48.723631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Fine-tune models","metadata":{}},{"cell_type":"code","source":"def evaluation_metric(y, y_pred):\n    r2 = r2_score(y, y_pred)\n    return r2","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:49.904922Z","iopub.execute_input":"2024-05-27T17:08:49.905286Z","iopub.status.idle":"2024-05-27T17:08:49.909830Z","shell.execute_reply.started":"2024-05-27T17:08:49.905256Z","shell.execute_reply":"2024-05-27T17:08:49.908830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LightGBM","metadata":{}},{"cell_type":"markdown","source":"1. gbdt. Finding the optimal parameters is painstaking. I start with \"learning_rate\"(), then add \"num_leaves\"(0.87088), then \"min_data_in_leaf\" and \"max_depth\"(0.870948), then \"n_estimators\", \"min_split_gain\"(0.87083), \"lambda_l1\", \"lambda_l2\",\"colsample_bytree\" and \"subsample\"(0.870706). The first three runs each takes about 1-2 hours. The rest much longer. As said in the lgbm parameters tuning page https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html, the most important parameters are \"num_leaves\", \"min_data_in_leaf\" and \"max_depth\". Adding \"learning_rate\" will capture the most important factors in here. Therefore the tuning is enough.","metadata":{}},{"cell_type":"markdown","source":"hyperparameter tuning:\nhttps://www.kaggle.com/code/zgrdenizelik/lgbm-0-86926-r2-score-explained#Hyperparameters-tuning","metadata":{}},{"cell_type":"code","source":"def lgbm_objective(trial):\n        params = {\n            \"objective\": \"regression\",\n            \"boosting\": \"gbdt\",\n            \"random_state\": 42,\n            \"n_jobs\": -1,\n            \"device\": 'gpu',\n            'learning_rate' :  0.012, \n            'n_estimators': 2000,\n            #\n            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 13), \n            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 140),\n            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0, 1),\n            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0, 1), \n            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n            \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0, 1),                                     \n        }    \n        \n        lgbm_reg = LGBMRegressor(**params)\n        \n        lgbm_reg.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n        \n        val_scores = evaluation_metric(y_val, lgbm_reg.predict(X_val))\n        return val_scores\n    \n# Set up the sampler for Optuna optimization\nsampler = TPESampler(seed=42)  # Using Tree-structured Parzen Estimator sampler for optimization    \n    \nlgbm_study = optuna.create_study(direction=\"maximize\", study_name=\"LGBMRegressor\", sampler=sampler)    ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T17:08:53.022330Z","iopub.execute_input":"2024-05-27T17:08:53.022729Z","iopub.status.idle":"2024-05-27T17:08:53.036312Z","shell.execute_reply.started":"2024-05-27T17:08:53.022700Z","shell.execute_reply":"2024-05-27T17:08:53.035277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TUNE = False\nif TUNE:\n    # Run the optimization process\n    lgbm_study.optimize(lambda trial: lgbm_objective(trial), n_trials=100)\n\n    # Get the best parameters after optimization\n    lgbm_best_params = lgbm_study.best_params\n\n    print('='*50)\n    print(lgbm_best_params)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T19:00:55.910277Z","iopub.execute_input":"2024-05-27T19:00:55.911079Z","iopub.status.idle":"2024-05-27T19:00:55.916076Z","shell.execute_reply.started":"2024-05-27T19:00:55.911044Z","shell.execute_reply":"2024-05-27T19:00:55.915174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv 0.870940 parameters\nlgbm_params_1 = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"random_state\": 42,\n    \"n_jobs\": -1,\n    \"device\": 'gpu',\n    'learning_rate' :  0.012, \n    'n_estimators': 2000,\n    #\n    'max_depth': 12, \n    'num_leaves': 109, \n    'min_data_in_leaf': 88, \n    'lambda_l1': 0.5296506093279638, \n    'lambda_l2': 0.5884899855294714, \n    'colsample_bytree': 0.6804587201173778, \n    'subsample': 0.7119148975720027, \n    'min_split_gain': 0.00023805431519668746\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-27T18:57:50.377065Z","iopub.execute_input":"2024-05-27T18:57:50.378078Z","iopub.status.idle":"2024-05-27T18:57:50.383930Z","shell.execute_reply.started":"2024-05-27T18:57:50.378043Z","shell.execute_reply":"2024-05-27T18:57:50.382943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_reg_1 = LGBMRegressor(**lgbm_params_1)\nlgbm_reg_1.fit(X_tr, y_tr)\nevaluation_metric(y_val, lgbm_reg_1.predict(X_val))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T18:57:52.926821Z","iopub.execute_input":"2024-05-27T18:57:52.927175Z","iopub.status.idle":"2024-05-27T18:59:00.967529Z","shell.execute_reply.started":"2024-05-27T18:57:52.927147Z","shell.execute_reply":"2024-05-27T18:59:00.966431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance = lgbm_reg_1.feature_importances_\n\nfeature_names = X_tr.columns\n\nsorted_indices = feature_importance.argsort()\nsorted_importance = feature_importance[sorted_indices]\nsorted_features = feature_names[sorted_indices]\n\n# Plot feature importance\nplt.figure(figsize=(12, 8))\ncolors = plt.cm.Paired.colors[:len(sorted_features)]  \nplt.barh(sorted_features, sorted_importance, color=colors)\nplt.xlabel('Importance', fontsize=12)\nplt.ylabel('Feature', fontsize=12)\nplt.title('LightGBM Feature Importance', fontsize=14)\nplt.gca().invert_yaxis() \n\nfor i, v in enumerate(sorted_importance):\n    plt.text(v + 0.02, i, f'{v:.2f}', color='black', va='center', fontsize=10)\n\nplt.tight_layout()  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T18:59:00.969276Z","iopub.execute_input":"2024-05-27T18:59:00.970385Z","iopub.status.idle":"2024-05-27T18:59:01.567235Z","shell.execute_reply.started":"2024-05-27T18:59:00.970335Z","shell.execute_reply":"2024-05-27T18:59:01.566341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Refit model on training data","metadata":{}},{"cell_type":"code","source":"lgbm_reg_1.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T18:59:01.568422Z","iopub.execute_input":"2024-05-27T18:59:01.568707Z","iopub.status.idle":"2024-05-27T19:00:03.870842Z","shell.execute_reply.started":"2024-05-27T18:59:01.568681Z","shell.execute_reply":"2024-05-27T19:00:03.869766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Prediction","metadata":{}},{"cell_type":"code","source":"pred = lgbm_reg_1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T19:00:03.872810Z","iopub.execute_input":"2024-05-27T19:00:03.873616Z","iopub.status.idle":"2024-05-27T19:00:53.779124Z","shell.execute_reply.started":"2024-05-27T19:00:03.873585Z","shell.execute_reply":"2024-05-27T19:00:53.778264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['id'] = test_ID\nsub['FloodProbability'] = pred","metadata":{"execution":{"iopub.status.busy":"2024-05-27T19:00:53.783190Z","iopub.execute_input":"2024-05-27T19:00:53.785096Z","iopub.status.idle":"2024-05-27T19:00:53.806752Z","shell.execute_reply.started":"2024-05-27T19:00:53.785065Z","shell.execute_reply":"2024-05-27T19:00:53.805945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('/kaggle/working/submission.csv',index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T19:00:53.807899Z","iopub.execute_input":"2024-05-27T19:00:53.808208Z","iopub.status.idle":"2024-05-27T19:00:55.909009Z","shell.execute_reply.started":"2024-05-27T19:00:53.808170Z","shell.execute_reply":"2024-05-27T19:00:55.908021Z"},"trusted":true},"execution_count":null,"outputs":[]}]}